{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "GHqCV2vtDGlS",
    "outputId": "580bc012-2944-48be-fb5d-b487c092297f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "svvwfuadFeK0",
    "outputId": "b2dfc400-c3e8-4c26-c828-946c35317e5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pkbIklxF0CY"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HbxnoHMGCjz"
   },
   "source": [
    "Open the data file as read only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iux5YmoVF9pb"
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('/content/drive/My Drive/AIML/Projects/Neural Network/SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hk5Q2WIVI0rb"
   },
   "source": [
    "**IMPORT DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HwPLERrtIy6j",
    "outputId": "fd93a413-7e31-430f-d4b0-7142986bc0ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(h5f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxwCB0ECMGBq"
   },
   "source": [
    "The SVHN dataset contains data split into 'X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val'. In the next step we will load this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD5eO27uHMPJ"
   },
   "source": [
    "**Load the training, test and validation set**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmDpHhWcHLJQ"
   },
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "y_val = h5f['y_val'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wl25UpHOLrey"
   },
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyRJskbLMoDt"
   },
   "source": [
    "Let us explore the shape of X_train, X_test and X_val & y_train, y_test and y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "RVave08YL9o5",
    "outputId": "d2ddf46e-ed66-414d-8d37-0d714dc40943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(18000, 32, 32)\n",
      "(60000, 32, 32)\n",
      "(42000,)\n",
      "(18000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTd22pVIT9S0"
   },
   "source": [
    "**Visualizing the numbers in the image dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "PytpHAmaTK4C",
    "outputId": "75ff5a82-f457-4903-ad72-2011d48a0187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f85b8fd7780>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Label: {}\".format(y_train[1]))\n",
    "plt.imshow(X_train[1],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bFeopXzcVogZ"
   },
   "source": [
    "As mentioned in the problem statement, there is a visbile distraction in the immage where the image is multidigit, with one digit \"6\" is fully visibile and other digit \"3\" is partially visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZWAKt4DHWDpf",
    "outputId": "cfbcf9a0-0fba-4127-cd2d-b4c985100c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [2 6 7 ... 7 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Label: {}\".format(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y6HQGXDtX9EA",
    "outputId": "bebfcfb5-432b-4caa-b619-9e8c7b6b42e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AYdBOAp7YHc3",
    "outputId": "4031439c-d444-46cb-cf56-292d342de879"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "-MoP5a_mscH9",
    "outputId": "c31aca78-6fab-4b51-c362-a436c25939bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.9745\n",
      "0.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "X_train = X_train / 254.9745\n",
    "X_val = X_val / 254.9745\n",
    "X_test = X_test / 254.9745\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFhiI8HKYPNC"
   },
   "source": [
    "*   x_train, x_test: array of image data with shape (num_samples, 32, 32)\n",
    "*   y_train, y_test: array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
    "X_train and X_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKadouBFaswy"
   },
   "source": [
    "**One-hot encode the class vector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgbkpShFbBCI"
   },
   "source": [
    "*   convert class vectors (integers) to binary class matrix\n",
    "*   convert y_train and y_test\n",
    "*   number of classes: 10\n",
    "*   we are doing this to use categorical_crossentropy as loss\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "RFdyVynIY5Ok",
    "outputId": "8673a42a-0f65-4e4c-df8e-01e6ed57a01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value before encoding: 2\n",
      "Shape of y_train: (42000, 10)\n",
      "One hot encoded value of y_train: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "print(\"Value before encoding:\", y_train[0])\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"One hot encoded value of y_train:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_osNQgfw1rol"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqYr65T6b3G-"
   },
   "source": [
    "# **Define the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5BpA7YJsvTH"
   },
   "source": [
    "##**MODEL 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNoCxC05NIAE"
   },
   "source": [
    "### **Initialize model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilFgA04hb7dq"
   },
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 32x32 to 1024\n",
    "model.add(tensorflow.keras.layers.Reshape((1024,),input_shape=(32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2RIvPuasu0HN"
   },
   "source": [
    "###**Applying Batch Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jH2WSDPivEUD"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "model.add(tensorflow.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6rGHGJYcgIU"
   },
   "source": [
    "###**Apply ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36P0Wo8rci-f"
   },
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "model.add(tensorflow.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(tensorflow.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "# Dropout layer\n",
    "#model.add(tensorflow.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tensorflow.keras.layers.Dense(80, activation='relu', name='Layer_3'))\n",
    "model.add(tensorflow.keras.layers.Dense(50, activation='relu', name='Layer_4'))\n",
    "# Dropout layer\n",
    "#model.add(tensorflow.keras.layers.Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5URPD8Pfc1ak"
   },
   "source": [
    "###**Adding output layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bAXB2G5c5nH"
   },
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tensorflow.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_eSYCJldIqS"
   },
   "source": [
    "###**Compile the model**\n",
    "Here we configure the model for training. We will specify an optimizer, loss function and a metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmVWmYRAdQn7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiWAvx9bdc8q"
   },
   "source": [
    "###**Summarize the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "K6QyEHmwdisH",
    "outputId": "ff4a4fcb-c715-4245-e0e8-5d45c2f340c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 241,836\n",
      "Trainable params: 239,788\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPLgRx4beARU"
   },
   "source": [
    "###**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TExmVle8eD6O",
    "outputId": "c1a1d6ac-b178-4f67-f681-77f332f8e974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.4149 - accuracy: 0.5250 - val_loss: 0.9733 - val_accuracy: 0.7057\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9115 - accuracy: 0.7170 - val_loss: 0.8282 - val_accuracy: 0.7459\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.7754 - accuracy: 0.7565 - val_loss: 0.7394 - val_accuracy: 0.7763\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.6904 - accuracy: 0.7848 - val_loss: 0.7060 - val_accuracy: 0.7889\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.6349 - accuracy: 0.8002 - val_loss: 0.6946 - val_accuracy: 0.7935\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.5928 - accuracy: 0.8148 - val_loss: 0.6670 - val_accuracy: 0.7978\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.5594 - accuracy: 0.8259 - val_loss: 0.6211 - val_accuracy: 0.8151\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.5328 - accuracy: 0.8339 - val_loss: 0.6357 - val_accuracy: 0.8123\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.5133 - accuracy: 0.8398 - val_loss: 0.6159 - val_accuracy: 0.8210\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.4877 - accuracy: 0.8463 - val_loss: 0.6225 - val_accuracy: 0.8217\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4688 - accuracy: 0.8499 - val_loss: 0.6070 - val_accuracy: 0.8279\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4465 - accuracy: 0.8580 - val_loss: 0.5912 - val_accuracy: 0.8315\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.4350 - accuracy: 0.8612 - val_loss: 0.6034 - val_accuracy: 0.8293\n",
      "Epoch 14/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.4287 - accuracy: 0.8623 - val_loss: 0.5801 - val_accuracy: 0.8395\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.4103 - accuracy: 0.8682 - val_loss: 0.5873 - val_accuracy: 0.8340\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3999 - accuracy: 0.8719 - val_loss: 0.5844 - val_accuracy: 0.8415\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8779 - val_loss: 0.6008 - val_accuracy: 0.8294\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3748 - accuracy: 0.8795 - val_loss: 0.6190 - val_accuracy: 0.8293\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3628 - accuracy: 0.8840 - val_loss: 0.6633 - val_accuracy: 0.8262\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3588 - accuracy: 0.8830 - val_loss: 0.6110 - val_accuracy: 0.8384\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3561 - accuracy: 0.8850 - val_loss: 0.6111 - val_accuracy: 0.8383\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3413 - accuracy: 0.8884 - val_loss: 0.6315 - val_accuracy: 0.8322\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3347 - accuracy: 0.8921 - val_loss: 0.6053 - val_accuracy: 0.8404\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.3302 - accuracy: 0.8947 - val_loss: 0.6227 - val_accuracy: 0.8403\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3178 - accuracy: 0.8959 - val_loss: 0.6056 - val_accuracy: 0.8425\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3084 - accuracy: 0.9004 - val_loss: 0.6413 - val_accuracy: 0.8454\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3053 - accuracy: 0.9008 - val_loss: 0.6180 - val_accuracy: 0.8409\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2989 - accuracy: 0.9026 - val_loss: 0.6446 - val_accuracy: 0.8354\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2908 - accuracy: 0.9043 - val_loss: 0.6238 - val_accuracy: 0.8429\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2882 - accuracy: 0.9057 - val_loss: 0.6386 - val_accuracy: 0.8409\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2813 - accuracy: 0.9092 - val_loss: 0.6497 - val_accuracy: 0.8421\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2784 - accuracy: 0.9097 - val_loss: 0.6454 - val_accuracy: 0.8417\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.2787 - accuracy: 0.9095 - val_loss: 0.6697 - val_accuracy: 0.8309\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2686 - accuracy: 0.9119 - val_loss: 0.6676 - val_accuracy: 0.8386\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2672 - accuracy: 0.9123 - val_loss: 0.6396 - val_accuracy: 0.8452\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2638 - accuracy: 0.9132 - val_loss: 0.6674 - val_accuracy: 0.8430\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2658 - accuracy: 0.9133 - val_loss: 0.6667 - val_accuracy: 0.8398\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2559 - accuracy: 0.9151 - val_loss: 0.6733 - val_accuracy: 0.8410\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2514 - accuracy: 0.9184 - val_loss: 0.6564 - val_accuracy: 0.8454\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.2466 - accuracy: 0.9187 - val_loss: 0.6730 - val_accuracy: 0.8413\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2472 - accuracy: 0.9192 - val_loss: 0.6897 - val_accuracy: 0.8441\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.2446 - accuracy: 0.9194 - val_loss: 0.6738 - val_accuracy: 0.8484\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2361 - accuracy: 0.9221 - val_loss: 0.7008 - val_accuracy: 0.8440\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2347 - accuracy: 0.9233 - val_loss: 0.6772 - val_accuracy: 0.8444\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2339 - accuracy: 0.9230 - val_loss: 0.6964 - val_accuracy: 0.8454\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2304 - accuracy: 0.9244 - val_loss: 0.6961 - val_accuracy: 0.8443\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2233 - accuracy: 0.9271 - val_loss: 0.6845 - val_accuracy: 0.8453\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2178 - accuracy: 0.9279 - val_loss: 0.7001 - val_accuracy: 0.8475\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2269 - accuracy: 0.9240 - val_loss: 0.6874 - val_accuracy: 0.8456\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2164 - accuracy: 0.9275 - val_loss: 0.7574 - val_accuracy: 0.8399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f85b250b4a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Toc4YoSGgEL3"
   },
   "source": [
    "###**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9i1lOkujgJEO",
    "outputId": "b8fa0b1a-4675-4123-9ef5-8840107efccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.7574 - accuracy: 0.8399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7574344277381897, 0.8399444222450256]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5vHBpyn3iMk"
   },
   "source": [
    "**There is opportunity to further minimize the loss and increase the accuracy. Hyperparameter tuning is needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHDln_224ewR"
   },
   "source": [
    "#**Model 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fB0Zhx-iTurL"
   },
   "source": [
    "###**Importing the SVHN dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jb8oGgvYANvh"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPnxz9yRB8sh"
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('/content/drive/My Drive/AIML/Projects/Neural Network/SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmhUpoiMB-nv"
   },
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "y_val = h5f['y_val'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "Gi8DFCGpAblb",
    "outputId": "c562459b-3da6-40bb-c617-78f643f58539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(42000,)\n",
      "(18000, 32, 32)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFyEYM-1Fr7v"
   },
   "source": [
    "###**Reshaping the data from 2D to 1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CyTBUlfmAhOu",
    "outputId": "3048dafb-ce98-469e-fac2-8ab97897d4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(42000, 1024)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "SBxbncr6BMnR",
    "outputId": "9c517ac6-51cb-4f27-c46a-bfea095f222a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.9745\n",
      "0.0\n",
      "0.0\n",
      "254.9745\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "print(X_test.min())\n",
    "print(X_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QF98VK6sF6u3"
   },
   "source": [
    "###**Normalizing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "oRgudJczBMPR",
    "outputId": "96cd6390-cbb1-4b8d-9db3-c2b227c58f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42000, 1024)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train / 254.9745\n",
    "X_test = X_test / 254.9745\n",
    "\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLrJTZgFGCah"
   },
   "source": [
    "###**One-hot encode the class vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "i0YD-5LfBMAd",
    "outputId": "f0eee7f7-cf5d-4ba7-d7cd-521772c4a4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[10])\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "print(y_train[10])\n",
    "print(y_test[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1-U3qtlGSRb"
   },
   "source": [
    "###**Visualizing the images and their labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "-WWVkx0GCki3",
    "outputId": "e088619c-dbcc-4f66-9c94-3ce9bed7590d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the below image: 2\n",
      "label for each of the below image: 6\n",
      "label for each of the below image: 7\n",
      "label for each of the below image: 4\n",
      "label for each of the below image: 4\n",
      "label for each of the below image: 0\n",
      "label for each of the below image: 3\n",
      "label for each of the below image: 0\n",
      "label for each of the below image: 7\n",
      "label for each of the below image: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(32, 32), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    print('label for each of the below image: %s' % (np.argmax(y_train[0:10][i])))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Md0wK-PGGb5i"
   },
   "source": [
    "###**Write a function to create a Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFDOU0k04h60"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 300\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(42000, 1024), activation='relu'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "73qYHzbSGxaI"
   },
   "source": [
    "###**Checking the Loss and Regularization**\n",
    "\n",
    "*   Double Check that the loss is reasonable\n",
    "*   Disable the regularization (Lambda = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "TJ9NjxeqDoh3",
    "outputId": "20faf81a-b5c7-4956-bb9f-bbd68b3ff496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.4114 - accuracy: 0.1028\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4049227237701416, 0.1033809557557106]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "train_and_test_loop(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imD1pd7THEoF"
   },
   "source": [
    "**The untrained model shows a accuracy close to 0.1%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luYtjdsGU3xj"
   },
   "source": [
    "**Increase the Lambda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "eWxHyW8tIA3E",
    "outputId": "4fe91c6a-d1de-47a5-aa5a-f0e6c3e7ee41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_3_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_3_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3292.3962 - accuracy: 0.1026\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_3_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[100.09819030761719, 0.09761904925107956]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 1e3\n",
    "train_and_test_loop(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O03HBnqBIHbB"
   },
   "source": [
    "**The Loss goes up when the Lambda is increased.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-7rwJZuVIZZ"
   },
   "source": [
    "##**Ensuring model architecture is fine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fsw9T9vQIVM9"
   },
   "source": [
    "###**Overfitting the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ol-0WhA1EMhw"
   },
   "outputs": [],
   "source": [
    "X_train_subset = X_train[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRiNcrD8EPnp"
   },
   "outputs": [],
   "source": [
    "y_train_subset = y_train[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bo1sB-CkEQpS"
   },
   "outputs": [],
   "source": [
    "X_train = X_train_subset\n",
    "y_train = y_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nk1dfHn2ETmi",
    "outputId": "a5fd0c84-6ad0-42f0-8a1a-d4845630fe59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1024)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "J3deKHpoEVh7",
    "outputId": "8613f262-739e-4a63-da8e-ff69a9360a78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bXnQo_P-Eghg",
    "outputId": "d5013968-f714-4d1c-81ff-9e1aa4711bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_6_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_6_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4623 - accuracy: 0.1000\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 970us/step - loss: 2.4452 - accuracy: 0.1000\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4137 - accuracy: 0.1000\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3703 - accuracy: 0.1000\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3185 - accuracy: 0.1000\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2631 - accuracy: 0.1500\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2064 - accuracy: 0.2000\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1504 - accuracy: 0.3000\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 879us/step - loss: 2.0985 - accuracy: 0.3000\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0518 - accuracy: 0.2000\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0102 - accuracy: 0.2500\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9755 - accuracy: 0.2500\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9478 - accuracy: 0.2500\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 990us/step - loss: 1.9254 - accuracy: 0.2000\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9066 - accuracy: 0.2000\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8917 - accuracy: 0.2500\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8793 - accuracy: 0.2500\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8684 - accuracy: 0.3000\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8582 - accuracy: 0.3000\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8485 - accuracy: 0.3500\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8383 - accuracy: 0.3500\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8279 - accuracy: 0.3500\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8177 - accuracy: 0.3000\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8075 - accuracy: 0.3000\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7970 - accuracy: 0.3000\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 869us/step - loss: 1.7864 - accuracy: 0.3000\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7765 - accuracy: 0.3500\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7671 - accuracy: 0.3500\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7578 - accuracy: 0.3500\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7488 - accuracy: 0.3500\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7403 - accuracy: 0.4000\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7323 - accuracy: 0.4500\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7245 - accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 962us/step - loss: 1.7169 - accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7093 - accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7018 - accuracy: 0.5500\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6941 - accuracy: 0.5500\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6865 - accuracy: 0.6000\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6789 - accuracy: 0.6000\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6715 - accuracy: 0.6500\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6642 - accuracy: 0.6500\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6569 - accuracy: 0.6500\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6498 - accuracy: 0.6500\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6426 - accuracy: 0.6500\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 974us/step - loss: 1.6354 - accuracy: 0.6500\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6284 - accuracy: 0.6000\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6215 - accuracy: 0.6000\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6148 - accuracy: 0.6000\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6081 - accuracy: 0.6000\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6014 - accuracy: 0.6000\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5948 - accuracy: 0.6000\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5883 - accuracy: 0.6000\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5818 - accuracy: 0.6000\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5755 - accuracy: 0.6000\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5693 - accuracy: 0.6500\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5632 - accuracy: 0.6500\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5573 - accuracy: 0.6500\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5513 - accuracy: 0.6500\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5454 - accuracy: 0.7000\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5395 - accuracy: 0.7000\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5338 - accuracy: 0.7000\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5281 - accuracy: 0.7000\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5223 - accuracy: 0.7000\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5166 - accuracy: 0.7000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5109 - accuracy: 0.7000\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5053 - accuracy: 0.7000\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 931us/step - loss: 1.4998 - accuracy: 0.7000\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4944 - accuracy: 0.7000\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4890 - accuracy: 0.7000\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4837 - accuracy: 0.6500\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 917us/step - loss: 1.4783 - accuracy: 0.6500\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4729 - accuracy: 0.6500\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4675 - accuracy: 0.6500\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4622 - accuracy: 0.6500\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4569 - accuracy: 0.6500\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4515 - accuracy: 0.6500\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4461 - accuracy: 0.6500\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4406 - accuracy: 0.6500\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4352 - accuracy: 0.6500\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4298 - accuracy: 0.6500\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4244 - accuracy: 0.6500\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4191 - accuracy: 0.6500\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4138 - accuracy: 0.6500\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4084 - accuracy: 0.7000\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.7000\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3977 - accuracy: 0.7000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 960us/step - loss: 1.3922 - accuracy: 0.7000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3868 - accuracy: 0.7000\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3813 - accuracy: 0.7000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3758 - accuracy: 0.7000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3704 - accuracy: 0.7000\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3649 - accuracy: 0.7000\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3594 - accuracy: 0.7000\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3540 - accuracy: 0.7000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3486 - accuracy: 0.7000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3432 - accuracy: 0.7000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3378 - accuracy: 0.7000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3325 - accuracy: 0.7000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3271 - accuracy: 0.7000\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3217 - accuracy: 0.7000\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3164 - accuracy: 0.7000\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3111 - accuracy: 0.7000\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3059 - accuracy: 0.7000\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3006 - accuracy: 0.7000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2955 - accuracy: 0.7000\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2904 - accuracy: 0.7000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2852 - accuracy: 0.7000\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2801 - accuracy: 0.7000\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2751 - accuracy: 0.7000\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2700 - accuracy: 0.7000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2649 - accuracy: 0.7500\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2598 - accuracy: 0.7500\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2547 - accuracy: 0.7500\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2497 - accuracy: 0.7500\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2446 - accuracy: 0.7500\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2396 - accuracy: 0.7500\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2346 - accuracy: 0.7500\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2297 - accuracy: 0.7500\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2247 - accuracy: 0.7500\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2197 - accuracy: 0.7500\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2148 - accuracy: 0.7500\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2098 - accuracy: 0.7500\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2048 - accuracy: 0.7500\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1999 - accuracy: 0.7500\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1949 - accuracy: 0.7500\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1900 - accuracy: 0.7500\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1851 - accuracy: 0.7500\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1802 - accuracy: 0.7500\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1752 - accuracy: 0.7500\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1703 - accuracy: 0.7500\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1654 - accuracy: 0.7500\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1605 - accuracy: 0.7500\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1556 - accuracy: 0.7500\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.7500\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1458 - accuracy: 0.7500\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.7500\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1361 - accuracy: 0.7500\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1313 - accuracy: 0.7500\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1265 - accuracy: 0.7500\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1218 - accuracy: 0.7500\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1170 - accuracy: 0.7500\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1122 - accuracy: 0.7500\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1075 - accuracy: 0.7500\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1028 - accuracy: 0.7500\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0980 - accuracy: 0.7500\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0933 - accuracy: 0.7500\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0886 - accuracy: 0.7500\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0839 - accuracy: 0.7500\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0792 - accuracy: 0.7500\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0746 - accuracy: 0.7500\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0699 - accuracy: 0.7500\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0652 - accuracy: 0.7500\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0606 - accuracy: 0.7500\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0559 - accuracy: 0.7500\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0513 - accuracy: 0.7500\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.7500\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.7500\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0375 - accuracy: 0.7500\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0329 - accuracy: 0.7500\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0283 - accuracy: 0.7500\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0237 - accuracy: 0.7500\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0192 - accuracy: 0.7500\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0146 - accuracy: 0.8000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0101 - accuracy: 0.8000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0056 - accuracy: 0.8000\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0011 - accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9966 - accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.8000\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.8000\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 909us/step - loss: 0.9833 - accuracy: 0.8000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.9789 - accuracy: 0.8000\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.9745 - accuracy: 0.8000\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9701 - accuracy: 0.8000\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9657 - accuracy: 0.8000\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.8000\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9569 - accuracy: 0.8000\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9525 - accuracy: 0.8500\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9481 - accuracy: 0.8500\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9437 - accuracy: 0.8500\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 948us/step - loss: 0.9394 - accuracy: 0.8500\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9350 - accuracy: 0.8500\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9306 - accuracy: 0.8500\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.8500\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9220 - accuracy: 0.8500\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9176 - accuracy: 0.8500\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.8500\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.8500\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.8500\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9003 - accuracy: 0.8500\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8960 - accuracy: 0.8500\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8917 - accuracy: 0.8500\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8874 - accuracy: 0.8500\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.8500\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.9000\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8747 - accuracy: 0.9000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8704 - accuracy: 0.9000\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8662 - accuracy: 0.9500\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8620 - accuracy: 0.9500\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8578 - accuracy: 0.9500\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8536 - accuracy: 0.9500\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8495 - accuracy: 0.9500\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8453 - accuracy: 0.9500\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8411 - accuracy: 0.9500\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8370 - accuracy: 0.9500\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8329 - accuracy: 0.9500\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8287 - accuracy: 0.9500\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8247 - accuracy: 0.9500\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 930us/step - loss: 0.8206 - accuracy: 0.9500\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8165 - accuracy: 0.9500\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8125 - accuracy: 0.9500\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8085 - accuracy: 0.9500\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8045 - accuracy: 0.9500\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8005 - accuracy: 0.9500\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7966 - accuracy: 0.9500\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.9500\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7888 - accuracy: 0.9500\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7849 - accuracy: 0.9500\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.9500\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7772 - accuracy: 0.9500\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7733 - accuracy: 0.9500\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7695 - accuracy: 0.9500\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7656 - accuracy: 0.9500\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7618 - accuracy: 0.9500\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7580 - accuracy: 0.9500\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.9500\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.9500\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7467 - accuracy: 0.9500\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7430 - accuracy: 0.9500\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7392 - accuracy: 0.9500\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.9500\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7318 - accuracy: 0.9500\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.9500\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.9500\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.9500\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.9500\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7133 - accuracy: 0.9500\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7097 - accuracy: 0.9500\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.9500\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.9500\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 979us/step - loss: 0.6988 - accuracy: 0.9500\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.9500\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 817us/step - loss: 0.6917 - accuracy: 0.9500\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.9500\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.9500\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.9500\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.9500\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.9500\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.9500\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.9500\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.9500\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.9500\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.9500\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.9500\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.9500\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.9500\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 908us/step - loss: 0.6432 - accuracy: 0.9500\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.9500\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.9500\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.9500\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.9500\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.9500\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.9500\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.9500\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.6099 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 872us/step - loss: 0.5969 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 980us/step - loss: 0.5535 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 924us/step - loss: 0.5475 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.5445 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.4745 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 924us/step - loss: 0.4171 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 919us/step - loss: 0.3267 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.2116 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_6_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16931845247745514, 1.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0\n",
    "train_and_test_loop(500, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYntOAhYIbwY"
   },
   "source": [
    "**Good indicator of the model architecture as for a very small loss the accuracy is going to 100. We can now consider fine tuning this model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwbUIMjXVxY-"
   },
   "source": [
    "##**Trials with Learnign rate and Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJ9TM1TAJH-_"
   },
   "source": [
    "###**Loading the original dataset again**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90L5V8GZJOaO"
   },
   "source": [
    "####**Import the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gf0l-Et3JLKY"
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('/content/drive/My Drive/AIML/Projects/Neural Network/SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBGlMppvJDRe"
   },
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "y_val = h5f['y_val'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yYuKg9s4E5IG",
    "outputId": "c6357d72-5f44-424e-fcb8-f0742eec81a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(42000, 1024)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tddFnjMdKdsg"
   },
   "source": [
    "###**Normalize the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "BXekAWo-KPlS",
    "outputId": "55f7d720-6d69-40c9-d7ce-212e6306ec9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 254.9745\n",
    "X_test = X_test / 254.9745\n",
    "\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVM2OcCNKl9O"
   },
   "source": [
    "###**One-hot encode the class vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "pH37LVXAKn7o",
    "outputId": "db9b89d4-3c17-428a-900f-f7b9a5bd99a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[10])\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sp0WcCyWeA1"
   },
   "source": [
    "###**Regularization and Learning Rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nCnD4fNLCIk"
   },
   "source": [
    "####**Start with small regularization and find learning rate that makes the loss go down**\n",
    "\n",
    "\n",
    "*   we start with Lambda(small regularization) = 1e-7\n",
    "*   we start with a small learning rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "sKa9Asp8K_kC",
    "outputId": "a3b72a03-8424-41e1-af1f-70e33afe4a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_9_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_9_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3442 - accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.3442 - accuracy: 0.0981\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3441 - accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3441 - accuracy: 0.0981\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3441 - accuracy: 0.0981\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3440 - accuracy: 0.0981\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3440 - accuracy: 0.0981\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3439 - accuracy: 0.0981\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3439 - accuracy: 0.0981\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3438 - accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.3438 - accuracy: 0.0981\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3437 - accuracy: 0.0981\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3437 - accuracy: 0.0981\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3436 - accuracy: 0.0982\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3436 - accuracy: 0.0981\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3435 - accuracy: 0.0982\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3435 - accuracy: 0.0983\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3434 - accuracy: 0.0982\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3434 - accuracy: 0.0982\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3433 - accuracy: 0.0982\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_9_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.343297243118286, 0.09819047898054123]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-7\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop(20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDNZ3Fh8Lln1"
   },
   "source": [
    "**The Loss is not reduced indicating that the learing rate may be too low.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfRYJRxAWyc3"
   },
   "source": [
    "####**Using high learing rate 1e8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "7xzWRfYAMCsY",
    "outputId": "e300677a-6bcd-4224-dc6a-5a907411825a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_12_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_12_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.1008\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_12_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.09966666996479034]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e8\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop(20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLoBcJeWMS7W"
   },
   "source": [
    "**The nan values in the loss indicate exploding loss and the learning rate is too high.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42WdBYSEMkPK"
   },
   "source": [
    "####**Train now with a value of learning rate between 1e-7 and 1e8**\n",
    "*  learning rate = 1e4\n",
    "*  regularization remains the small, lambda = 1e-7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "QZywaoMvMoNn",
    "outputId": "00f09820-21bf-4a15-90c8-764afb5126e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_15_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_15_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: inf - accuracy: 0.0984\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: inf - accuracy: 0.1036\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: inf - accuracy: 0.0980\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2005486135464343626948194336768.0000 - accuracy: 0.1005\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 210841385307274197713970790400.0000 - accuracy: 0.0999\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 22136329006775605421460684800.0000 - accuracy: 0.0989\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2324039910585669181448912896.0000 - accuracy: 0.1014\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 244025705458118597080514560.0000 - accuracy: 0.0989\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 25626502791730451602997248.0000 - accuracy: 0.1017\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2691567310098722193408000.0000 - accuracy: 0.0995\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 282737641930982611222528.0000 - accuracy: 0.1014\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 29704648767426340585472.0000 - accuracy: 0.1018\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3121245617446979633152.0000 - accuracy: 0.1002\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 328014753047437639680.0000 - accuracy: 0.1015\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 34476354770265178112.0000 - accuracy: 0.1015\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3624194559434555392.0000 - accuracy: 0.1005\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 381034483295453184.0000 - accuracy: 0.0999\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 40066298205437952.0000 - accuracy: 0.0986\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 4213629742219264.0000 - accuracy: 0.0984\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 443196131770368.0000 - accuracy: 0.0994\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_15_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[114239922503680.0, 0.09966666996479034]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e4\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop(20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDZbBJ7HM92h"
   },
   "source": [
    "**The Loss is still exploding and learnign rate still seems too high. We wiil have to optimize the hyperparameteres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9IVEyqANS_K"
   },
   "source": [
    "# **Hyperparameter Optimization**\n",
    "\n",
    "## Cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Kp-5_-jWMbA4",
    "outputId": "aef76b80-9139-4408-e2a5-7b528b82f81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_18_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_18_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3582 - accuracy: 0.0906\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3575 - accuracy: 0.0904\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3566 - accuracy: 0.0901\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3559 - accuracy: 0.0901\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3551 - accuracy: 0.0897\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3543 - accuracy: 0.0895\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3536 - accuracy: 0.0893\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3528 - accuracy: 0.0892\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3521 - accuracy: 0.0890\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3514 - accuracy: 0.0890\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3507 - accuracy: 0.0890\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3500 - accuracy: 0.0890\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3494 - accuracy: 0.0890\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3487 - accuracy: 0.0890\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3480 - accuracy: 0.0892\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3474 - accuracy: 0.0892\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3468 - accuracy: 0.0890\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3462 - accuracy: 0.0891\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3456 - accuracy: 0.0889\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3450 - accuracy: 0.0889\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3444 - accuracy: 0.0889\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3438 - accuracy: 0.0892\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3433 - accuracy: 0.0893\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3427 - accuracy: 0.0894\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 2.3422 - accuracy: 0.0891\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 2.3416 - accuracy: 0.0891\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3411 - accuracy: 0.0892\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3406 - accuracy: 0.0893\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3401 - accuracy: 0.0895\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3396 - accuracy: 0.0896\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3391 - accuracy: 0.0901\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3386 - accuracy: 0.0902\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3381 - accuracy: 0.0903\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3377 - accuracy: 0.0902\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3372 - accuracy: 0.0905\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3368 - accuracy: 0.0906\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3363 - accuracy: 0.0908\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3359 - accuracy: 0.0910\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3354 - accuracy: 0.0911\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3350 - accuracy: 0.0911\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3346 - accuracy: 0.0912\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3342 - accuracy: 0.0911\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3338 - accuracy: 0.0911\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3334 - accuracy: 0.0916\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3330 - accuracy: 0.0915\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3326 - accuracy: 0.0917\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3322 - accuracy: 0.0917\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3319 - accuracy: 0.0918\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3315 - accuracy: 0.0919\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3311 - accuracy: 0.0921\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3308 - accuracy: 0.0920\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3304 - accuracy: 0.0924\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3301 - accuracy: 0.0928\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3297 - accuracy: 0.0930\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3294 - accuracy: 0.0933\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3291 - accuracy: 0.0933\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3287 - accuracy: 0.0936\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3284 - accuracy: 0.0938\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3281 - accuracy: 0.0942\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3278 - accuracy: 0.0943\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3275 - accuracy: 0.0946\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3272 - accuracy: 0.0948\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3269 - accuracy: 0.0953\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3266 - accuracy: 0.0952\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3263 - accuracy: 0.0953\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3260 - accuracy: 0.0955\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3257 - accuracy: 0.0955\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3254 - accuracy: 0.0959\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3252 - accuracy: 0.0963\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3249 - accuracy: 0.0962\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3246 - accuracy: 0.0968\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3244 - accuracy: 0.0972\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3241 - accuracy: 0.0975\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3239 - accuracy: 0.0976\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3236 - accuracy: 0.0980\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3234 - accuracy: 0.0983\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3231 - accuracy: 0.0985\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3229 - accuracy: 0.0987\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3226 - accuracy: 0.0988\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3224 - accuracy: 0.0991\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3222 - accuracy: 0.0995\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3220 - accuracy: 0.0999\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3217 - accuracy: 0.1001\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3215 - accuracy: 0.1002\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3213 - accuracy: 0.1002\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3211 - accuracy: 0.1003\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3209 - accuracy: 0.1004\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3207 - accuracy: 0.1004\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3205 - accuracy: 0.1007\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3203 - accuracy: 0.1008\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3201 - accuracy: 0.1008\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3199 - accuracy: 0.1008\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3197 - accuracy: 0.1012\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3195 - accuracy: 0.1015\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3193 - accuracy: 0.1018\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3191 - accuracy: 0.1020\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3189 - accuracy: 0.1021\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3187 - accuracy: 0.1019\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3185 - accuracy: 0.1021\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3184 - accuracy: 0.1021\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_18_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 1/100: Best_val_acc: [2.3182828426361084, 0.10207142680883408], lr: 1.1163747459386872e-06, Lambda: 1.160801382789272e-06\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_21_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_21_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3162 - accuracy: 0.1137\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2805 - accuracy: 0.1683\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2579 - accuracy: 0.2165\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2270 - accuracy: 0.2776\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1833 - accuracy: 0.3287\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1220 - accuracy: 0.3742\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.0355 - accuracy: 0.4218\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.9256 - accuracy: 0.4653\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.8067 - accuracy: 0.4977\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.6903 - accuracy: 0.5297\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.5830 - accuracy: 0.5624\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.4922 - accuracy: 0.5856\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4129 - accuracy: 0.6043\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.3495 - accuracy: 0.6179\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2964 - accuracy: 0.6293\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2468 - accuracy: 0.6419\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.2103 - accuracy: 0.6490\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1664 - accuracy: 0.6609\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1371 - accuracy: 0.6684\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1107 - accuracy: 0.6748\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0857 - accuracy: 0.6824\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.0589 - accuracy: 0.6868\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0377 - accuracy: 0.6946\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0239 - accuracy: 0.6969\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0028 - accuracy: 0.7028\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.9841 - accuracy: 0.7069\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.9613 - accuracy: 0.7168\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.9475 - accuracy: 0.7205\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.9317 - accuracy: 0.7244\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.9169 - accuracy: 0.7279\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.9048 - accuracy: 0.7336\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8943 - accuracy: 0.7346\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8799 - accuracy: 0.7423\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8751 - accuracy: 0.7389\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8651 - accuracy: 0.7443\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8440 - accuracy: 0.7491\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8279 - accuracy: 0.7555\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8146 - accuracy: 0.7595\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8146 - accuracy: 0.7577\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8070 - accuracy: 0.7620\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8095 - accuracy: 0.7575\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7847 - accuracy: 0.7657\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7768 - accuracy: 0.7702\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7675 - accuracy: 0.7740\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7564 - accuracy: 0.7762\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7536 - accuracy: 0.7770\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7417 - accuracy: 0.7803\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7329 - accuracy: 0.7835\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7234 - accuracy: 0.7851\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7129 - accuracy: 0.7894\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7142 - accuracy: 0.7900\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7073 - accuracy: 0.7904\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6921 - accuracy: 0.7955\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6918 - accuracy: 0.7949\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6866 - accuracy: 0.7975\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6772 - accuracy: 0.8010\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6691 - accuracy: 0.8031\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6699 - accuracy: 0.8006\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6721 - accuracy: 0.8015\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6616 - accuracy: 0.8034\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6524 - accuracy: 0.8074\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6547 - accuracy: 0.8059\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6571 - accuracy: 0.8044\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6413 - accuracy: 0.8090\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6317 - accuracy: 0.8134\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6273 - accuracy: 0.8149\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6189 - accuracy: 0.8179\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6063 - accuracy: 0.8221\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6142 - accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6180 - accuracy: 0.8166\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6048 - accuracy: 0.8209\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5917 - accuracy: 0.8255\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.5924 - accuracy: 0.8249\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5982 - accuracy: 0.8218\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5835 - accuracy: 0.8277\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5840 - accuracy: 0.8267\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5741 - accuracy: 0.8312\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5728 - accuracy: 0.8313\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5823 - accuracy: 0.8275\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5642 - accuracy: 0.8332\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5558 - accuracy: 0.8369\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5575 - accuracy: 0.8363\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5502 - accuracy: 0.8380\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5539 - accuracy: 0.8368\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5583 - accuracy: 0.8357\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5540 - accuracy: 0.8371\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5438 - accuracy: 0.8408\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5449 - accuracy: 0.8391\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5414 - accuracy: 0.8398\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5378 - accuracy: 0.8405\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5334 - accuracy: 0.8419\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5226 - accuracy: 0.8467\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5343 - accuracy: 0.8421\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5166 - accuracy: 0.8487\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5159 - accuracy: 0.8483\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5130 - accuracy: 0.8497\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5105 - accuracy: 0.8485\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5059 - accuracy: 0.8496\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5089 - accuracy: 0.8508\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.4982 - accuracy: 0.8527\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_21_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 2/100: Best_val_acc: [0.5066519379615784, 0.8485714197158813], lr: 0.008379343897065506, Lambda: 8.769885777620072e-07\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_24_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_24_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 34805039104.0000 - accuracy: 0.1014\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 48193142784.0000 - accuracy: 0.1010\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 30550073344.0000 - accuracy: 0.0988\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 19004004352.0000 - accuracy: 0.0959\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 11817606144.0000 - accuracy: 0.0985\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 7348860928.0000 - accuracy: 0.0995\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 4570035200.0000 - accuracy: 0.1013\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2842027776.0000 - accuracy: 0.1002\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1767446400.0000 - accuracy: 0.0999\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1099191424.0000 - accuracy: 0.0996\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 683611904.0000 - accuracy: 0.0975\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 425162720.0000 - accuracy: 0.1003\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 264429440.0000 - accuracy: 0.0999\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 164465072.0000 - accuracy: 0.1005\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 102293192.0000 - accuracy: 0.0991\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 63625184.0000 - accuracy: 0.0973\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 39574948.0000 - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 24616194.0000 - accuracy: 0.1028\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 15311956.0000 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 9524661.0000 - accuracy: 0.0995\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 5924855.5000 - accuracy: 0.0981\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3685658.5000 - accuracy: 0.0989\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2292775.7500 - accuracy: 0.1004\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1426321.5000 - accuracy: 0.1016\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 887324.7500 - accuracy: 0.1017\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 552022.7500 - accuracy: 0.0987\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 343432.3750 - accuracy: 0.1001\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 213665.9688 - accuracy: 0.0989\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 132935.0625 - accuracy: 0.1009\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 82709.3672 - accuracy: 0.1006\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 51461.4375 - accuracy: 0.0974\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 32020.0957 - accuracy: 0.1004\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 19924.1543 - accuracy: 0.1015\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 12398.1738 - accuracy: 0.0984\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 7715.4829 - accuracy: 0.1009\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4801.8423 - accuracy: 0.1007\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2988.8865 - accuracy: 0.0998\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1860.7888 - accuracy: 0.1021\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1158.8239 - accuracy: 0.1029\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 722.0156 - accuracy: 0.0994\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 450.1988 - accuracy: 0.0984\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 281.0471 - accuracy: 0.0985\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 175.7803 - accuracy: 0.0993\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 110.2710 - accuracy: 0.1008\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 69.5054 - accuracy: 0.0987\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 44.1269 - accuracy: 0.0988\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 28.3401 - accuracy: 0.1008\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 18.5128 - accuracy: 0.0998\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 12.3940 - accuracy: 0.1008\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 8.5884 - accuracy: 0.0992\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 6.2200 - accuracy: 0.1018\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 4.7471 - accuracy: 0.1015\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8290 - accuracy: 0.0988\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.2580 - accuracy: 0.0985\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.8949 - accuracy: 0.1003\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.6733 - accuracy: 0.0985\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.5387 - accuracy: 0.1005\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.4541 - accuracy: 0.1005\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.4025 - accuracy: 0.1011\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3685 - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3498 - accuracy: 0.1016\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3333 - accuracy: 0.0980\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3232 - accuracy: 0.1016\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3238 - accuracy: 0.1016\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3189 - accuracy: 0.0992\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3245 - accuracy: 0.0987\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3178 - accuracy: 0.1011\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3139 - accuracy: 0.1001\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3116 - accuracy: 0.0986\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3122 - accuracy: 0.1017\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3142 - accuracy: 0.1008\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3157 - accuracy: 0.0972\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3114 - accuracy: 0.0998\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3119 - accuracy: 0.1024\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3121 - accuracy: 0.1019\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3121 - accuracy: 0.1021\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3141 - accuracy: 0.0980\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3126 - accuracy: 0.0993\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3095 - accuracy: 0.0994\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3131 - accuracy: 0.0987\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3128 - accuracy: 0.0976\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3137 - accuracy: 0.0992\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3126 - accuracy: 0.0994\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3105 - accuracy: 0.1012\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3107 - accuracy: 0.1015\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3157 - accuracy: 0.0985\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3123 - accuracy: 0.1002\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3145 - accuracy: 0.1011\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3120 - accuracy: 0.0993\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3117 - accuracy: 0.0985\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3147 - accuracy: 0.0972\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3117 - accuracy: 0.1000\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3107 - accuracy: 0.0993\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3129 - accuracy: 0.0993\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3141 - accuracy: 0.0989\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3104 - accuracy: 0.0990\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3133 - accuracy: 0.1004\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3117 - accuracy: 0.0982\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3097 - accuracy: 0.1010\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3112 - accuracy: 0.1008\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_24_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 3/100: Best_val_acc: [2.318603515625, 0.09971428662538528], lr: 3.908314838025265, Lambda: 6.847651009628818e-05\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_27_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_27_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3234 - accuracy: 0.1043\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.1134\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3000 - accuracy: 0.1199\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2974 - accuracy: 0.1255\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2949 - accuracy: 0.1321\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2927 - accuracy: 0.1344\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2907 - accuracy: 0.1442\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2890 - accuracy: 0.1501\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2873 - accuracy: 0.1513\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2857 - accuracy: 0.1558\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2841 - accuracy: 0.1612\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2826 - accuracy: 0.1641\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2810 - accuracy: 0.1686\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2792 - accuracy: 0.1716\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2774 - accuracy: 0.1789\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2758 - accuracy: 0.1824\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2742 - accuracy: 0.1884\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2726 - accuracy: 0.1927\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2709 - accuracy: 0.1991\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2692 - accuracy: 0.2058\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2675 - accuracy: 0.2090\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2658 - accuracy: 0.2112\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2641 - accuracy: 0.2199\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2624 - accuracy: 0.2253\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2607 - accuracy: 0.2300\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2589 - accuracy: 0.2372\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2570 - accuracy: 0.2377\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2551 - accuracy: 0.2450\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2533 - accuracy: 0.2502\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2512 - accuracy: 0.2510\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2491 - accuracy: 0.2615\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2471 - accuracy: 0.2648\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2449 - accuracy: 0.2649\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2427 - accuracy: 0.2726\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2405 - accuracy: 0.2782\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2380 - accuracy: 0.2862\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2358 - accuracy: 0.2878\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2334 - accuracy: 0.2896\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.2307 - accuracy: 0.2978\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2281 - accuracy: 0.3019\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2255 - accuracy: 0.3050\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2228 - accuracy: 0.3137\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2199 - accuracy: 0.3120\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2171 - accuracy: 0.3195\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2142 - accuracy: 0.3223\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2113 - accuracy: 0.3314\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2082 - accuracy: 0.3304\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2051 - accuracy: 0.3362\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2019 - accuracy: 0.3390\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1986 - accuracy: 0.3465\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1952 - accuracy: 0.3463\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.1918 - accuracy: 0.3501\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1882 - accuracy: 0.3523\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1846 - accuracy: 0.3593\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.1808 - accuracy: 0.3614\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1770 - accuracy: 0.3651\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1731 - accuracy: 0.3682\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.1690 - accuracy: 0.3689\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.1649 - accuracy: 0.3745\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1607 - accuracy: 0.3757\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1563 - accuracy: 0.3803\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1519 - accuracy: 0.3806\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1475 - accuracy: 0.3820\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1427 - accuracy: 0.3863\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1379 - accuracy: 0.3898\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.1331 - accuracy: 0.3913\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1281 - accuracy: 0.3926\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1230 - accuracy: 0.3967\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1179 - accuracy: 0.3975\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.1125 - accuracy: 0.4001\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.1071 - accuracy: 0.4013\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.1016 - accuracy: 0.4067\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0959 - accuracy: 0.4041\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.0902 - accuracy: 0.4074\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0843 - accuracy: 0.4109\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0783 - accuracy: 0.4125\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0722 - accuracy: 0.4148\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0660 - accuracy: 0.4146\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0597 - accuracy: 0.4171\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.0533 - accuracy: 0.4197\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0468 - accuracy: 0.4213\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0402 - accuracy: 0.4211\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0334 - accuracy: 0.4225\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0267 - accuracy: 0.4264\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0197 - accuracy: 0.4291\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0128 - accuracy: 0.4298\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0059 - accuracy: 0.4307\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9987 - accuracy: 0.4344\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9915 - accuracy: 0.4365\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9842 - accuracy: 0.4385\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9767 - accuracy: 0.4381\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9694 - accuracy: 0.4417\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9619 - accuracy: 0.4448\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9544 - accuracy: 0.4440\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.9468 - accuracy: 0.4505\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9391 - accuracy: 0.4494\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9317 - accuracy: 0.4505\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9238 - accuracy: 0.4549\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9162 - accuracy: 0.4563\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.9083 - accuracy: 0.4591\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_27_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 4/100: Best_val_acc: [1.9041179418563843, 0.45892858505249023], lr: 0.000538375033108269, Lambda: 7.277317364422697e-05\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_30_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_30_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3566 - accuracy: 0.0964\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3358 - accuracy: 0.0955\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 2.3242 - accuracy: 0.0964\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3180 - accuracy: 0.0991\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3145 - accuracy: 0.1018\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3124 - accuracy: 0.1032\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3111 - accuracy: 0.1033\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3101 - accuracy: 0.1027\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3095 - accuracy: 0.1030\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3090 - accuracy: 0.1029\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3085 - accuracy: 0.1025\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3082 - accuracy: 0.1032\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3078 - accuracy: 0.1032\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3075 - accuracy: 0.1036\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3072 - accuracy: 0.1039\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3070 - accuracy: 0.1044\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3067 - accuracy: 0.1048\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.3065 - accuracy: 0.1055\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3062 - accuracy: 0.1061\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3060 - accuracy: 0.1062\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3058 - accuracy: 0.1065\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3056 - accuracy: 0.1073\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.3053 - accuracy: 0.1079\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 2.3051 - accuracy: 0.1086\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 2.3049 - accuracy: 0.1088\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3047 - accuracy: 0.1091\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3045 - accuracy: 0.1094\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3043 - accuracy: 0.1097\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3041 - accuracy: 0.1107\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3039 - accuracy: 0.1113\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3037 - accuracy: 0.1115\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3035 - accuracy: 0.1118\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3033 - accuracy: 0.1119\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3031 - accuracy: 0.1123\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3029 - accuracy: 0.1128\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3027 - accuracy: 0.1130\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3025 - accuracy: 0.1128\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3023 - accuracy: 0.1134\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3021 - accuracy: 0.1141\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3019 - accuracy: 0.1143\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3017 - accuracy: 0.1151\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3015 - accuracy: 0.1150\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3014 - accuracy: 0.1152\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3012 - accuracy: 0.1160\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3010 - accuracy: 0.1160\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3008 - accuracy: 0.1166\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3006 - accuracy: 0.1170\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3004 - accuracy: 0.1172\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3002 - accuracy: 0.1178\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3001 - accuracy: 0.1186\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2999 - accuracy: 0.1189\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2997 - accuracy: 0.1192\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2995 - accuracy: 0.1202\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2993 - accuracy: 0.1201\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2992 - accuracy: 0.1207\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2990 - accuracy: 0.1210\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2988 - accuracy: 0.1213\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2986 - accuracy: 0.1219\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2985 - accuracy: 0.1225\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2983 - accuracy: 0.1223\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2981 - accuracy: 0.1232\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2979 - accuracy: 0.1231\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2978 - accuracy: 0.1232\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2976 - accuracy: 0.1235\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2974 - accuracy: 0.1237\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2973 - accuracy: 0.1243\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2971 - accuracy: 0.1245\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2970 - accuracy: 0.1255\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2968 - accuracy: 0.1260\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2966 - accuracy: 0.1266\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2965 - accuracy: 0.1265\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2963 - accuracy: 0.1275\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2962 - accuracy: 0.1278\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2960 - accuracy: 0.1278\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2959 - accuracy: 0.1281\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2957 - accuracy: 0.1283\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2956 - accuracy: 0.1295\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2955 - accuracy: 0.1293\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2953 - accuracy: 0.1298\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2952 - accuracy: 0.1301\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2950 - accuracy: 0.1303\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2949 - accuracy: 0.1308\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2948 - accuracy: 0.1307\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2946 - accuracy: 0.1313\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2945 - accuracy: 0.1316\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2944 - accuracy: 0.1322\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2942 - accuracy: 0.1320\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2941 - accuracy: 0.1325\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2940 - accuracy: 0.1328\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2938 - accuracy: 0.1336\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2937 - accuracy: 0.1337\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2936 - accuracy: 0.1344\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2935 - accuracy: 0.1344\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2933 - accuracy: 0.1344\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2932 - accuracy: 0.1344\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2931 - accuracy: 0.1351\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2930 - accuracy: 0.1359\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2928 - accuracy: 0.1358\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2927 - accuracy: 0.1363\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2926 - accuracy: 0.1365\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_30_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 5/100: Best_val_acc: [2.2925050258636475, 0.1366666704416275], lr: 4.179585140260466e-05, Lambda: 0.00012064474190812282\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_33_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_33_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.3681 - accuracy: 0.1225\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.2968 - accuracy: 0.1456\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2773 - accuracy: 0.1393\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3199 - accuracy: 0.0993\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3091 - accuracy: 0.1009\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2908 - accuracy: 0.1132\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3081 - accuracy: 0.0996\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3034 - accuracy: 0.1056\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2986 - accuracy: 0.1071\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2953 - accuracy: 0.1093\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3040 - accuracy: 0.1008\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3007 - accuracy: 0.1108\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3045 - accuracy: 0.0999\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.2984 - accuracy: 0.1089\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3017 - accuracy: 0.1033\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3046 - accuracy: 0.1015\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3035 - accuracy: 0.1014\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2926 - accuracy: 0.1083\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3072 - accuracy: 0.0986\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3036 - accuracy: 0.1014\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.2908 - accuracy: 0.1211\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3004 - accuracy: 0.1033\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3043 - accuracy: 0.0986\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3035 - accuracy: 0.0993\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3037 - accuracy: 0.1005\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3036 - accuracy: 0.0979\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.0989\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3034 - accuracy: 0.0990\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3030 - accuracy: 0.1020\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3040 - accuracy: 0.1091\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3039 - accuracy: 0.0998\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.1014\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3036 - accuracy: 0.1005\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3036 - accuracy: 0.0973\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3033 - accuracy: 0.0988\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3032 - accuracy: 0.1010\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3032 - accuracy: 0.1005\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3030 - accuracy: 0.0972\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3029 - accuracy: 0.1012\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3035 - accuracy: 0.0993\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3034 - accuracy: 0.1004\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.1008\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.0986\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3034 - accuracy: 0.1009\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3035 - accuracy: 0.1004\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3033 - accuracy: 0.1009\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3032 - accuracy: 0.1012\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3033 - accuracy: 0.0995\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3034 - accuracy: 0.1026\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3032 - accuracy: 0.0992\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.0987\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3033 - accuracy: 0.0980\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3032 - accuracy: 0.1014\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.2834 - accuracy: 0.1147\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3079 - accuracy: 0.0988\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3041 - accuracy: 0.0992\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3039 - accuracy: 0.0965\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.0985\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3035 - accuracy: 0.0993\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3035 - accuracy: 0.0991\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3032 - accuracy: 0.0977\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3031 - accuracy: 0.1008\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.3033 - accuracy: 0.0984\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3034 - accuracy: 0.1013\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3039 - accuracy: 0.0970\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3032 - accuracy: 0.0968\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3034 - accuracy: 0.0963\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.1003\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3032 - accuracy: 0.1004\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3037 - accuracy: 0.0982\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3036 - accuracy: 0.0987\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3035 - accuracy: 0.1004\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3032 - accuracy: 0.0981\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.0994\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3034 - accuracy: 0.0988\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.1007\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3029 - accuracy: 0.0987\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.1013\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3033 - accuracy: 0.0991\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3032 - accuracy: 0.1023\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3032 - accuracy: 0.0996\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3039 - accuracy: 0.0998\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3035 - accuracy: 0.0968\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3034 - accuracy: 0.1002\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.0989\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3035 - accuracy: 0.1007\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3033 - accuracy: 0.0974\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3032 - accuracy: 0.0988\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3032 - accuracy: 0.0995\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3032 - accuracy: 0.0979\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3033 - accuracy: 0.1005\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3035 - accuracy: 0.0983\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.3034 - accuracy: 0.0999\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3037 - accuracy: 0.0982\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3036 - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3033 - accuracy: 0.0994\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3033 - accuracy: 0.0993\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.3035 - accuracy: 0.0980\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 2.3034 - accuracy: 0.0994\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_33_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 6/100: Best_val_acc: [2.303741931915283, 0.09990476071834564], lr: 0.3391759269964905, Lambda: 0.0020929328924635384\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_36_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_36_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.1008\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_36_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 7/100: Best_val_acc: [nan, 0.09966666996479034], lr: 216.59162191951515, Lambda: 0.0017339959014233191\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_39_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_39_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0996\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_39_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 8/100: Best_val_acc: [nan, 0.09966666996479034], lr: 57.93717514158356, Lambda: 1.2599325450138539e-06\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_42_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_42_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0993\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 3s 66ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: nan - accuracy: 0.0997\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_42_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n",
      "Try 9/100: Best_val_acc: [nan, 0.09966666996479034], lr: 302.4182421252784, Lambda: 0.005907810296251388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-7.0, 3.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "    best_acc = train_and_test_loop(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcrW04wyolsE"
   },
   "source": [
    "**Try 6/100: Best_val_acc: None, lr: 0.03373622959273333, Lambda: 1.65628473556203e-05**\n",
    "\n",
    "**Number of loops 100, 500, 300**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Fb502zmAU1jw",
    "outputId": "9a8b831f-56ce-479c-8cc3-f3d6d8c075ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_45_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_45_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (1000, 1024).\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.2991 - accuracy: 0.1298\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.1504 - accuracy: 0.2893\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.8589 - accuracy: 0.3821\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.5293 - accuracy: 0.4947\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3340 - accuracy: 0.5630\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.1892 - accuracy: 0.6222\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.1369 - accuracy: 0.6414\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1053 - accuracy: 0.6473\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0296 - accuracy: 0.6780\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.9320 - accuracy: 0.7133\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8923 - accuracy: 0.7252\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8568 - accuracy: 0.7370\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8410 - accuracy: 0.7398\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8487 - accuracy: 0.7365\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7697 - accuracy: 0.7655\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7574 - accuracy: 0.7685\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7472 - accuracy: 0.7704\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7436 - accuracy: 0.7701\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7221 - accuracy: 0.7783\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7176 - accuracy: 0.7792\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7110 - accuracy: 0.7825\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6772 - accuracy: 0.7910\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6540 - accuracy: 0.8004\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6435 - accuracy: 0.8049\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6364 - accuracy: 0.8066\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6047 - accuracy: 0.8169\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6132 - accuracy: 0.8136\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5950 - accuracy: 0.8200\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5825 - accuracy: 0.8239\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5839 - accuracy: 0.8213\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5553 - accuracy: 0.8309\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5668 - accuracy: 0.8264\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5544 - accuracy: 0.8300\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5361 - accuracy: 0.8370\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5421 - accuracy: 0.8340\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5370 - accuracy: 0.8338\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5160 - accuracy: 0.8415\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5114 - accuracy: 0.8424\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4900 - accuracy: 0.8503\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4892 - accuracy: 0.8500\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5009 - accuracy: 0.8475\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4788 - accuracy: 0.8540\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4671 - accuracy: 0.8570\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4631 - accuracy: 0.8582\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4531 - accuracy: 0.8608\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4548 - accuracy: 0.8620\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4507 - accuracy: 0.8621\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4364 - accuracy: 0.8662\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4324 - accuracy: 0.8677\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4138 - accuracy: 0.8739\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4314 - accuracy: 0.8678\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4188 - accuracy: 0.8715\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4161 - accuracy: 0.8704\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4151 - accuracy: 0.8724\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4034 - accuracy: 0.8774\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4063 - accuracy: 0.8749\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.4087 - accuracy: 0.8725\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3964 - accuracy: 0.8786\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3782 - accuracy: 0.8830\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3817 - accuracy: 0.8834\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3742 - accuracy: 0.8858\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3713 - accuracy: 0.8858\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3756 - accuracy: 0.8830\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3679 - accuracy: 0.8857\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3571 - accuracy: 0.8892\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3606 - accuracy: 0.8883\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3536 - accuracy: 0.8907\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3518 - accuracy: 0.8902\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3485 - accuracy: 0.8923\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3480 - accuracy: 0.8929\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3434 - accuracy: 0.8928\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3360 - accuracy: 0.8950\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3505 - accuracy: 0.8899\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3289 - accuracy: 0.8972\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3301 - accuracy: 0.8964\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3225 - accuracy: 0.8990\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3188 - accuracy: 0.9012\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3054 - accuracy: 0.9041\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3171 - accuracy: 0.8986\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3031 - accuracy: 0.9055\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2997 - accuracy: 0.9069\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3177 - accuracy: 0.8978\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3202 - accuracy: 0.8984\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3100 - accuracy: 0.9019\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3054 - accuracy: 0.9016\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2898 - accuracy: 0.9087\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2929 - accuracy: 0.9072\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2913 - accuracy: 0.9085\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2710 - accuracy: 0.9142\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2658 - accuracy: 0.9166\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2823 - accuracy: 0.9097\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2722 - accuracy: 0.9140\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2773 - accuracy: 0.9112\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2834 - accuracy: 0.9106\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2712 - accuracy: 0.9139\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.3008 - accuracy: 0.9035\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2800 - accuracy: 0.9107\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2630 - accuracy: 0.9165\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2690 - accuracy: 0.9144\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2517 - accuracy: 0.9204\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2503 - accuracy: 0.9205\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2488 - accuracy: 0.9202\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2384 - accuracy: 0.9257\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2335 - accuracy: 0.9257\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2359 - accuracy: 0.9259\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2300 - accuracy: 0.9266\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2311 - accuracy: 0.9268\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2213 - accuracy: 0.9301\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2287 - accuracy: 0.9272\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2485 - accuracy: 0.9195\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2266 - accuracy: 0.9281\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2253 - accuracy: 0.9275\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2240 - accuracy: 0.9278\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2184 - accuracy: 0.9295\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2157 - accuracy: 0.9300\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2176 - accuracy: 0.9296\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2171 - accuracy: 0.9296\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2131 - accuracy: 0.9315\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2036 - accuracy: 0.9342\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1964 - accuracy: 0.9373\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1860 - accuracy: 0.9409\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1977 - accuracy: 0.9376\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2044 - accuracy: 0.9334\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1941 - accuracy: 0.9378\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1984 - accuracy: 0.9349\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2033 - accuracy: 0.9351\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1910 - accuracy: 0.9397\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1851 - accuracy: 0.9414\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1920 - accuracy: 0.9383\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1888 - accuracy: 0.9386\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1937 - accuracy: 0.9378\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1979 - accuracy: 0.9335\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1782 - accuracy: 0.9427\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1761 - accuracy: 0.9434\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.1724 - accuracy: 0.9453\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1599 - accuracy: 0.9489\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1594 - accuracy: 0.9493\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1658 - accuracy: 0.9455\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1799 - accuracy: 0.9419\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1715 - accuracy: 0.9435\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1658 - accuracy: 0.9454\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1523 - accuracy: 0.9512\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1456 - accuracy: 0.9534\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1575 - accuracy: 0.9481\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1548 - accuracy: 0.9496\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1462 - accuracy: 0.9538\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1427 - accuracy: 0.9541\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1371 - accuracy: 0.9564\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1524 - accuracy: 0.9503\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1942 - accuracy: 0.9351\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1530 - accuracy: 0.9498\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1453 - accuracy: 0.9534\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1516 - accuracy: 0.9501\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1562 - accuracy: 0.9487\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1475 - accuracy: 0.9525\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1371 - accuracy: 0.9562\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1341 - accuracy: 0.9572\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1418 - accuracy: 0.9531\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1437 - accuracy: 0.9529\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1443 - accuracy: 0.9530\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1375 - accuracy: 0.9556\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1421 - accuracy: 0.9533\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1339 - accuracy: 0.9567\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1204 - accuracy: 0.9630\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1252 - accuracy: 0.9601\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1381 - accuracy: 0.9557\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1523 - accuracy: 0.9485\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1324 - accuracy: 0.9554\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1268 - accuracy: 0.9593\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1132 - accuracy: 0.9649\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1146 - accuracy: 0.9631\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1295 - accuracy: 0.9563\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1196 - accuracy: 0.9622\n",
      "Epoch 174/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1228 - accuracy: 0.9601\n",
      "Epoch 175/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1092 - accuracy: 0.9651\n",
      "Epoch 176/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1011 - accuracy: 0.9677\n",
      "Epoch 177/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1110 - accuracy: 0.9641\n",
      "Epoch 178/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1068 - accuracy: 0.9647\n",
      "Epoch 179/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1157 - accuracy: 0.9609\n",
      "Epoch 180/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1094 - accuracy: 0.9646\n",
      "Epoch 181/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1032 - accuracy: 0.9675\n",
      "Epoch 182/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1177 - accuracy: 0.9607\n",
      "Epoch 183/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1153 - accuracy: 0.9621\n",
      "Epoch 184/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1117 - accuracy: 0.9635\n",
      "Epoch 185/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1199 - accuracy: 0.9608\n",
      "Epoch 186/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1091 - accuracy: 0.9649\n",
      "Epoch 187/300\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.1074 - accuracy: 0.9640\n",
      "Epoch 188/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0924 - accuracy: 0.9701\n",
      "Epoch 189/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1008 - accuracy: 0.9681\n",
      "Epoch 190/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1023 - accuracy: 0.9671\n",
      "Epoch 191/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1088 - accuracy: 0.9642\n",
      "Epoch 192/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1311 - accuracy: 0.9555\n",
      "Epoch 193/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1039 - accuracy: 0.9663\n",
      "Epoch 194/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0872 - accuracy: 0.9715\n",
      "Epoch 195/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1031 - accuracy: 0.9664\n",
      "Epoch 196/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1257 - accuracy: 0.9571\n",
      "Epoch 197/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1015 - accuracy: 0.9667\n",
      "Epoch 198/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0850 - accuracy: 0.9730\n",
      "Epoch 199/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0832 - accuracy: 0.9736\n",
      "Epoch 200/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0914 - accuracy: 0.9708\n",
      "Epoch 201/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0921 - accuracy: 0.9704\n",
      "Epoch 202/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0895 - accuracy: 0.9708\n",
      "Epoch 203/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0907 - accuracy: 0.9696\n",
      "Epoch 204/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1075 - accuracy: 0.9631\n",
      "Epoch 205/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0948 - accuracy: 0.9690\n",
      "Epoch 206/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0768 - accuracy: 0.9755\n",
      "Epoch 207/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0741 - accuracy: 0.9767\n",
      "Epoch 208/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1135 - accuracy: 0.9615\n",
      "Epoch 209/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0979 - accuracy: 0.9679\n",
      "Epoch 210/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0892 - accuracy: 0.9700\n",
      "Epoch 211/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0787 - accuracy: 0.9747\n",
      "Epoch 212/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0719 - accuracy: 0.9774\n",
      "Epoch 213/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0887 - accuracy: 0.9702\n",
      "Epoch 214/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0991 - accuracy: 0.9673\n",
      "Epoch 215/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0667 - accuracy: 0.9793\n",
      "Epoch 216/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0629 - accuracy: 0.9813\n",
      "Epoch 217/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0745 - accuracy: 0.9764\n",
      "Epoch 218/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0848 - accuracy: 0.9725\n",
      "Epoch 219/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0950 - accuracy: 0.9688\n",
      "Epoch 220/300\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.1076 - accuracy: 0.9631\n",
      "Epoch 221/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0845 - accuracy: 0.9726\n",
      "Epoch 222/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0763 - accuracy: 0.9753\n",
      "Epoch 223/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0704 - accuracy: 0.9768\n",
      "Epoch 224/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0766 - accuracy: 0.9745\n",
      "Epoch 225/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.1018 - accuracy: 0.9652\n",
      "Epoch 226/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0794 - accuracy: 0.9741\n",
      "Epoch 227/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0592 - accuracy: 0.9822\n",
      "Epoch 228/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0596 - accuracy: 0.9814\n",
      "Epoch 229/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0507 - accuracy: 0.9854\n",
      "Epoch 230/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0499 - accuracy: 0.9860\n",
      "Epoch 231/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0549 - accuracy: 0.9838\n",
      "Epoch 232/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0472 - accuracy: 0.9868\n",
      "Epoch 233/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0466 - accuracy: 0.9869\n",
      "Epoch 234/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0427 - accuracy: 0.9881\n",
      "Epoch 235/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0425 - accuracy: 0.9889\n",
      "Epoch 236/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0470 - accuracy: 0.9865\n",
      "Epoch 237/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0478 - accuracy: 0.9867\n",
      "Epoch 238/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0422 - accuracy: 0.9882\n",
      "Epoch 239/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0394 - accuracy: 0.9898\n",
      "Epoch 240/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0661 - accuracy: 0.9781\n",
      "Epoch 241/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0889 - accuracy: 0.9688\n",
      "Epoch 242/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0673 - accuracy: 0.9780\n",
      "Epoch 243/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0586 - accuracy: 0.9810\n",
      "Epoch 244/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0533 - accuracy: 0.9836\n",
      "Epoch 245/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0583 - accuracy: 0.9815\n",
      "Epoch 246/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0673 - accuracy: 0.9773\n",
      "Epoch 247/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0609 - accuracy: 0.9798\n",
      "Epoch 248/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0483 - accuracy: 0.9857\n",
      "Epoch 249/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0551 - accuracy: 0.9824\n",
      "Epoch 250/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0499 - accuracy: 0.9847\n",
      "Epoch 251/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0418 - accuracy: 0.9880\n",
      "Epoch 252/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0402 - accuracy: 0.9882\n",
      "Epoch 253/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0538 - accuracy: 0.9828\n",
      "Epoch 254/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0739 - accuracy: 0.9752\n",
      "Epoch 255/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0829 - accuracy: 0.9721\n",
      "Epoch 256/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0826 - accuracy: 0.9720\n",
      "Epoch 257/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0709 - accuracy: 0.9757\n",
      "Epoch 258/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0733 - accuracy: 0.9755\n",
      "Epoch 259/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0897 - accuracy: 0.9691\n",
      "Epoch 260/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0619 - accuracy: 0.9799\n",
      "Epoch 261/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0894 - accuracy: 0.9692\n",
      "Epoch 262/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0945 - accuracy: 0.9687\n",
      "Epoch 263/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0734 - accuracy: 0.9749\n",
      "Epoch 264/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0821 - accuracy: 0.9717\n",
      "Epoch 265/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0846 - accuracy: 0.9716\n",
      "Epoch 266/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0678 - accuracy: 0.9770\n",
      "Epoch 267/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0564 - accuracy: 0.9812\n",
      "Epoch 268/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0430 - accuracy: 0.9864\n",
      "Epoch 269/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0366 - accuracy: 0.9899\n",
      "Epoch 270/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0273 - accuracy: 0.9929\n",
      "Epoch 271/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0296 - accuracy: 0.9920\n",
      "Epoch 272/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0251 - accuracy: 0.9940\n",
      "Epoch 273/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0331 - accuracy: 0.9908\n",
      "Epoch 274/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0301 - accuracy: 0.9921\n",
      "Epoch 275/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0253 - accuracy: 0.9941\n",
      "Epoch 276/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0196 - accuracy: 0.9962\n",
      "Epoch 277/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0193 - accuracy: 0.9959\n",
      "Epoch 278/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0164 - accuracy: 0.9970\n",
      "Epoch 279/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0172 - accuracy: 0.9967\n",
      "Epoch 280/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0144 - accuracy: 0.9981\n",
      "Epoch 281/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0153 - accuracy: 0.9976\n",
      "Epoch 282/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0141 - accuracy: 0.9977\n",
      "Epoch 283/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0137 - accuracy: 0.9978\n",
      "Epoch 284/300\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.0132 - accuracy: 0.9982\n",
      "Epoch 285/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0138 - accuracy: 0.9982\n",
      "Epoch 286/300\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.0147 - accuracy: 0.9977\n",
      "Epoch 287/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0153 - accuracy: 0.9975\n",
      "Epoch 288/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0119 - accuracy: 0.9985\n",
      "Epoch 289/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0114 - accuracy: 0.9988\n",
      "Epoch 290/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0104 - accuracy: 0.9990\n",
      "Epoch 291/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "Epoch 292/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0095 - accuracy: 0.9991\n",
      "Epoch 293/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0095 - accuracy: 0.9991\n",
      "Epoch 294/300\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.0085 - accuracy: 0.9994\n",
      "Epoch 295/300\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.0079 - accuracy: 0.9995\n",
      "Epoch 296/300\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0088 - accuracy: 0.9994\n",
      "Epoch 297/300\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0077 - accuracy: 0.9995\n",
      "Epoch 298/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0075 - accuracy: 0.9997\n",
      "Epoch 299/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0065 - accuracy: 0.9996\n",
      "Epoch 300/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0068 - accuracy: 0.9996\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 42000, 1024) for input Tensor(\"dense_45_input:0\", shape=(None, 42000, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 1024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006066175177693367, 0.9997380971908569]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.06369765080380183\n",
    "Lambda = 1.1457046135394623e-07\n",
    "train_and_test_loop(300, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSTxi5cDE0ti"
   },
   "source": [
    "**The Model Accuracy is highly imporved by tuning the hyperparameters.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_GMO5siIUP7"
   },
   "source": [
    "##**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1Le7DRtrVxC"
   },
   "source": [
    "**The Neural Network is able to clsssify the images in the test dataset with an accuracy of 99.96% and loss of 0.0060 by keeping the epochs = 300, lr = 0.06369765080380183 & lambda = 1.1457046135394623e-07**\n",
    "\n",
    "**The model overfits with increasing loss if the epochs are set to 500 and the lr and lambda values have been already optimized by cross validation strategy of coarse and fine stages of vaidation.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Network_Project_V1_0_Group8_NOV_B_Batch_Abhishek+Kadam_14Jun2020",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
